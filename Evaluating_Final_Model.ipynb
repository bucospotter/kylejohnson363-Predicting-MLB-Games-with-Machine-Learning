{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Final Model\n",
    "In this notebook, I evaluate the final model by comparing its performance to the baselines created in the Data Exploration and Visualization notebook.  Below I bring in a the necessary libraries, data and a copy of the model from the previous notebook along with its necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "pickle_in=open(\"cleaned_data.pickle\",\"rb\")\n",
    "df=pickle.load(pickle_in)\n",
    "# I need to drop two columns that I left in for the visualization notebook\n",
    "df.drop(['home_score','away_score'],axis=1,inplace=True)\n",
    "# This is the same function from the previous notebook and it will be used to\n",
    "# evaluate model performance\n",
    "def calc_return(X_analyse):\n",
    "    total_risk=[]\n",
    "    total_reward=[]\n",
    "    equal_bet_return=[]\n",
    "    for i in range(len(X_analyse)):\n",
    "        k=pd.DataFrame(X_analyse.iloc[i]).transpose()\n",
    "        k.reset_index(drop=True,inplace=True)\n",
    "        if int(k.preds[0])==1:\n",
    "            if int(k.real[0])==1:\n",
    "                if int(k.home_money[0])<0:\n",
    "                    risk=k.home_money[0]\n",
    "                    reward=100\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=k.home_money[0]\n",
    "            else:\n",
    "                if k.home_money[0]<0:\n",
    "                    risk=k.home_money[0]\n",
    "                    reward=k.home_money[0]\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=-100\n",
    "        else:\n",
    "            if int(k.real[0])==0:\n",
    "                if k.away_money[0]<0:\n",
    "                    risk=k.away_money[0]\n",
    "                    reward=100\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=k.away_money[0]\n",
    "            else:\n",
    "                if k.away_money[0]<0:\n",
    "                    risk=k.away_money[0]\n",
    "                    reward=k.away_money[0]\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=-100\n",
    "        total_risk.append(risk)\n",
    "        total_reward.append(reward)\n",
    "        equal_bet_winnings=reward/-risk*100\n",
    "        equal_bet_return.append(equal_bet_winnings)\n",
    "    natural_ror=round(-np.mean(total_reward)/np.mean(total_risk)*100,2)\n",
    "    equal_bet_ror=round(np.mean(equal_bet_return),2)\n",
    "    return natural_ror,equal_bet_ror\n",
    "# This is a function for creating train-test splits that will work with my way of\n",
    "# scoring model performance based on real world return on risk\n",
    "def test_split(data,test_size,random_state):\n",
    "    shuf_df=data.sample(frac=1,random_state=random_state)\n",
    "    shuf_df.reset_index(drop=True,inplace=True)\n",
    "    df2=shuf_df.copy()\n",
    "    # This seperates the dataframe into data and target \n",
    "    X_temp=df2[df2.columns[1:]]\n",
    "    y=df2.home_win\n",
    "    # This standardized the data\n",
    "    scaler=StandardScaler()\n",
    "    X_s = scaler.fit_transform(X_temp)\n",
    "    X=pd.DataFrame(X_s)\n",
    "    # This does the train-test split in a way that I can carry through the odds values in order to calculate\n",
    "    # the real-world usefulness of the model\n",
    "    if len(X)==len(y):\n",
    "        split_value=int(round(len(X)*(1-test_size),0))\n",
    "        X_train=X.iloc[0:split_value]\n",
    "        X_test=X.iloc[split_value:len(X)]\n",
    "        y_train=y.iloc[0:split_value]\n",
    "        y_test=y.iloc[split_value:len(X)]\n",
    "        home_money=shuf_df.iloc[:,-2]\n",
    "        away_money=shuf_df.iloc[:,-1]\n",
    "    return X_train,X_test,y_train,y_test,home_money,away_money,split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_svm_xg=pd.DataFrame([])\n",
    "for j in range(0,50):\n",
    "    X_train,X_test,y_train,y_test,home_money,away_money,split_value=test_split(df,.1,j*3)\n",
    "    svm_clf=svm.SVC(C=6,kernel='linear',random_state=j*3)\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    svm_pred=svm_clf.predict(X_test)\n",
    "    boost=xgb.XGBClassifier(learning_rate=.001,max_depth=50,\n",
    "                            min_child_weight=10,n_estimators=200,subsample=.4,gamma=10,random_state=j*3)\n",
    "    boost.fit(X_train,y_train)\n",
    "    boost_pred=boost.predict(X_test)\n",
    "    bets=pd.DataFrame([])\n",
    "    for i in range(len(y_test)):\n",
    "        if svm_pred[i]+boost_pred[i]==2:\n",
    "            bets=bets.append(pd.DataFrame({'preds':1,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "        else:\n",
    "            None\n",
    "        if svm_pred[i]+boost_pred[i]==0:\n",
    "            bets=bets.append(pd.DataFrame({'preds':0,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "    svm_acc=round(accuracy_score(y_test,svm_pred)*100,1)\n",
    "    boost_acc=round(accuracy_score(y_test,boost_pred)*100,1)\n",
    "    combo_acc=round(accuracy_score(bets.real,bets.preds)*100,1)\n",
    "    nat,equal=calc_return(bets)\n",
    "    results_svm_xg=results_svm_xg.append(pd.DataFrame({'fold':j+1,'svm_acc':svm_acc,\n",
    "                                                       'boost_acc':boost_acc,'combo_acc':combo_acc,\n",
    "                                                       'nat':nat,'equal':equal},index=[0]),ignore_index=True)\n",
    "print('Average SVM Accuracy Score: ',round(results_svm_xg.svm_acc.mean(),2))\n",
    "print('Average XG Boost Accuracy Score: ',round(results_svm_xg.boost_acc.mean(),2))\n",
    "print('Average Combined Accuracy Score: ',round(results_svm_xg.combo_acc.mean(),2))\n",
    "print('Average Natural Wager Return on Risk: ',round(results_svm_xg.nat.mean(),2))\n",
    "print('Average Equal Wager Return on Risk: ',round(results_svm_xg.equal.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a re-creation of the winning model from the previous notebook.  Below I import the baseline results from the notebook Data Exploration and Visualization to compare the model to.  I use Kernel Density Estimation plots to visualize the distributions of the two datasets being compared.  I use Welch's t-test to try to confirm the null hypothesis in each case:\n",
    "\n",
    "#### Accuracy score hypothesis:\n",
    "$H_{0}$= The average accuracy score is the same for the baseline and for my model. \n",
    "\n",
    "$H_{a}$= The average accuracy score is the not same for the baseline and for my model. \n",
    "#### Natural Wager Return on Risk hypothesis:\n",
    "$H_{0}$= The average return on risk is the same for the baseline and for my model. \n",
    "\n",
    "$H_{a}$= The average return on risk is the not same for the baseline and for my model. \n",
    "#### Equal Wager Return on Risk hypothesis:\n",
    "$H_{0}$= The average return on risk is the same for the baseline and for my model. \n",
    "\n",
    "$H_{a}$= The average return on risk is the not same for the baseline and for my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in=open(\"baseline_accuracy.pickle\",\"rb\")\n",
    "baseline_accuracy=pickle.load(pickle_in)\n",
    "baseline_accuracy=pd.DataFrame(baseline_accuracy,columns=['acc'])\n",
    "pickle_in=open(\"baseline_natural_ror.pickle\",\"rb\")\n",
    "baseline_natural_ror=pickle.load(pickle_in)\n",
    "baseline_natural_ror=pd.DataFrame(baseline_natural_ror,columns=['nat'])\n",
    "pickle_in=open(\"baseline_equal_ror.pickle\",\"rb\")\n",
    "baseline_equal_ror=pickle.load(pickle_in)\n",
    "baseline_equal_ror=pd.DataFrame(baseline_equal_ror,columns=['equal'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "baseline_accuracy.acc.plot.kde(label='Vegas')\n",
    "results_svm_xg.combo_acc.plot.kde(label='Model')\n",
    "plt.title('Accuracy Score: Vegas vs. Model')\n",
    "plt.xlabel('Percent of Games Predicted Correctly')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "results = stats.ttest_ind(results_svm_xg.combo_acc,baseline_accuracy.acc, equal_var=False)\n",
    "print('Coefficient: ',round(results[0],3))\n",
    "print('p-value: ',round(results[1],3))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "baseline_natural_ror.nat.plot.kde(label='Vegas')\n",
    "results_svm_xg.nat.plot.kde(label='Model')\n",
    "plt.title('Natural Wager Return on Risk: Vegas vs. Model')\n",
    "plt.xlabel('Percent Return on Risk')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "results = stats.ttest_ind(results_svm_xg.nat,baseline_natural_ror.nat, equal_var=False)\n",
    "print('Coefficient: ',round(results[0],3))\n",
    "print('p-value: ',round(results[1],3))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "baseline_equal_ror.equal.plot.kde(label='Vegas')\n",
    "results_svm_xg.equal.plot.kde(label='Model')\n",
    "plt.title('Equal Wager Return on Risk: Vegas vs. Model')\n",
    "plt.xlabel('Percent Return on Risk')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "results = stats.ttest_ind(results_svm_xg.equal,baseline_equal_ror.equal, equal_var=False)\n",
    "print('Coefficient: ',round(results[0],3))\n",
    "print('p-value: ',round(results[1],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all three cases the p-value is less than .05 and thus we can reject the null hypothesis in all three cases.  This test shows that my model predicts MLB games better than the Vegas odds in a statistically significant way.  \n",
    "\n",
    "In order to get a sense of the potential usefulness of this model for making a profit in the betting markets, we can assume that the returns used in the above analysis are along the same lines as those that you would get from daily bets on games that the model predicts.  Obviously everyday won't be a clean 6% return; there will be a lot of variation and thus we can use these random sample return on risk as a proxy for daily return on risk.  Below is a visualization of a hypothetical betting account value over time using the four different methods that \"re-invests\" all profits.  Keep in mind, this is not an accurate representation of expected returns, it is simply a visualization of the difference in predictive power between my model and the Vegas odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=1000\n",
    "vegas_nat=start\n",
    "vegas_equal=start\n",
    "model_nat=start\n",
    "model_equal=start\n",
    "perf=pd.DataFrame([])\n",
    "for i in range(len(baseline_natural_ror.nat)):\n",
    "    vegas_nat+=vegas_nat*(baseline_natural_ror.nat[i]*.01)\n",
    "    vegas_equal+=start*(baseline_equal_ror.equal[i]*.01)\n",
    "    model_nat+=start*(results_svm_xg.nat[i]*.01)\n",
    "    model_equal+=start*(results_svm_xg.equal[i]*.01)\n",
    "    perf=perf.append(pd.DataFrame({'day':i+1,'vegas_nat':round(vegas_nat,0),'vegas_equal':vegas_equal,\n",
    "                                  'model_nat':model_nat,'model_equal':model_equal},index=[0]),\n",
    "                     ignore_index=True)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(perf.day,perf.model_equal,label=\"Model Equal       Final Value: ${0}\".format(int(perf.model_equal[49])))\n",
    "plt.plot(perf.day,perf.model_nat,label=\"Model Natural    Final Value: ${0}\".format(int(perf.model_nat[49])))\n",
    "plt.plot(perf.day,perf.vegas_nat,label=\"Vegas Natural    Final Value: ${0}\".format(int(perf.vegas_nat[49]))) \n",
    "plt.plot(perf.day,perf.vegas_equal,label=\"Vegas Equal       Final Value: ${0}\".format(int(perf.vegas_equal[49])))\n",
    "plt.legend()   \n",
    "plt.title('Hypothetical Betting Account Value Over Time')\n",
    "plt.xlabel('Betting Day')\n",
    "plt.ylabel('Betting Account Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    "- I was able to create a model that predicts MLB games more accurately and more profitably than the Vegas odds in a statistically significant way.  I did this by querying data from several online baseball databases and then optimizing several different classification models, before combining them to vote on the outcome of each game. \n",
    "- Oddly enough, it seems that always betting with the Vegas odds is a profitable strategy but using the model created in this project is potentially almose twice as profitable.\n",
    "\n",
    "# Future Work:\n",
    "For further exploration, I would use more types of data (new and highly advanced statistics) and more games from previous seasons. I would also automate the process of gathering the necessary data for today's games and publishing a report of which games to bet on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}